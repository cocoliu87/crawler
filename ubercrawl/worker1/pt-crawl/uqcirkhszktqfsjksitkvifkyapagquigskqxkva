uqcirkhszktqfsjksitkvifkyapagquigskqxkva page 10000 Collective perception of a group of people For other uses, see Wisdom of the crowd (disambiguation). The wisdom of the crowd is the collective opinion of a diverse independent group of individuals rather than that of a single expert. This process, while not new to the Information Age, has been pushed into the mainstream spotlight by social information sites such as Quora, Reddit, Stack Exchange, Wikipedia, Yahoo! Answers, and other web resources which rely on collective human knowledge.[1] An explanation for this phenomenon is that there is idiosyncratic noise associated with each individual judgment, and taking the average over a large number of responses will go some way toward canceling the effect of this noise.[2] Trial by jury can be understood as at least partly relying on wisdom of the crowd, compared to bench trial which relies on one or a few experts. In politics, sometimes sortition is held as an example of what wisdom of the crowd would look like. Decision-making would happen by a diverse group instead of by a fairly homogenous political group or party. Research within cognitive science has sought to model the relationship between wisdom of the crowd effects and individual cognition. A large group's aggregated answers to questions involving quantity estimation, general world knowledge, and spatial reasoning has generally been found to be as good as, but often superior to, the answer given by any of the individuals within the group. Jury theorems from social choice theory provide formal arguments for wisdom of the crowd given a variety of more or less plausible assumptions. Both the assumptions and the conclusions remain controversial, even though the theorems themselves are not. The oldest and simplest is Condorcet's jury theorem (1785). Examples[edit] Aristotle is credited as the first person to write about the "wisdom of the crowd" in his work Politics.[3][4] According to Aristotle, "it is possible that the many, though not individually good men, yet when they come together may be better, not individually but collectively, than those who are so, just as public dinners to which many contribute are better than those supplied at one man's cost".[5] Sir Francis Galton by Charles Wellington Furse, given to the National Portrait Gallery, London in 1954 The classic wisdom-of-the-crowds finding involves point estimation of a continuous quantity. At a 1906 country fair in Plymouth, 800 people participated in a contest to estimate the weight of a slaughtered and dressed ox. Statistician Francis Galton observed that the median guess, 1207 pounds, was accurate within 1% of the true weight of 1198 pounds.[6] This has contributed to the insight in cognitive science that a crowd's individual judgments can be modeled as a probability distribution of responses with the median centered near the true value of the quantity to be estimated.[7] In recent years, the "wisdom of the crowd" phenomenon has been leveraged in business strategy, advertising spaces, and also political research. Firms such as Napkin Labs aggregate consumer feedback and brand impressions for clients. Meanwhile, companies such as Trada invoke crowds to design advertisements based on clients' requirements.[8] Lastly, political preferences are aggregated to predict or nowcast political elections.[9][10][11] Non-human examples are prevalent. For example, the golden shiner is a fish that prefers shady areas. The single shiner has a very difficult time finding shady regions in a body of water whereas a large group is much more efficient at finding the shade.[12] Higher-dimensional problems and modeling[edit] Although classic wisdom-of-the-crowds findings center on point estimates of single continuous quantities, the phenomenon also scales up to higher-dimensional problems that do not lend themselves to aggregation methods such as taking the mean. More complex models have been developed for these purposes. A few examples of higher-dimensional problems that exhibit wisdom-of-the-crowds effects include: Combinatorial problems such as minimum spanning trees and the traveling salesman problem, in which participants must find the shortest route between an array of points. Models of these problems either break the problem into common pieces (the local decomposition method of aggregation) or find solutions that are most similar to the individual human solutions (the global similarity aggregation method).[2][13] Ordering problems such as the order of the U.S. presidents or world cities by population. A useful approach in this situation is Thurstonian modeling, which each participant has access to the ground truth ordering but with varying degrees of stochastic noise, leading to variance in the final ordering given by different individuals.[14][15][16][17] Multi-armed bandit problems, in which participants choose from a set of alternatives with fixed but unknown reward rates with the goal of maximizing return after a number of trials. To accommodate mixtures of decision processes and individual differences in probabilities of winning and staying with a given alternative versus losing and shifting to another alternative, hierarchical Bayesian models have been employed which include parameters for individual people drawn from Gaussian distributions.[18] Surprisingly popular[edit] In further exploring the ways to improve the results, a new technique called the "surprisingly popular" was developed by scientists at MIT's Sloan Neuroeconomics Lab in collaboration with Princeton University. For a given question, people are asked to give two responses: What they think the right answer is, and what they think popular opinion will be. The averaged difference between the two indicates the correct answer. It was found that the "surprisingly popular" algorithm reduces errors by 21.3 percent in comparison to simple majority votes, and by 24.2 percent in comparison to basic confidence-weighted votes where people express how confident they are of their answers and 22.2 percent compared to advanced confidence-weighted votes, where one only uses the answers with the highest average.[19] Definition of crowd[edit] This section possibly contains original research. Please improve it by verifying the claims made and adding inline citations. Statements consisting only of original research should be removed. (June 2016) (template removal help) In the context of wisdom of the crowd, the term crowd takes on a broad meaning. One definition characterizes a crowd as a group of people amassed by an open call for participation.[20] While crowds are often leveraged in online applications, they can also be utilized in offline contexts.[20] In some cases, members of a crowd may be offered monetary incentives for participation.[21] Certain applications of "wisdom of the crowd", such as jury duty in the United States, mandate crowd participation.[22] Analogues with individual cognition: the "crowd within"[edit] The insight that crowd responses to an estimation task can be modeled as a sample from a probability distribution invites comparisons with individual cognition. In particular, it is possible that individual cognition is probabilistic in the sense that individual estimates are drawn from an "internal probability distribution." If this is the case, then two or more estimates of the same quantity from the same person should average to a value closer to ground truth than either of the individual judgments, since the effect of statistical noise within each of these judgments is reduced. This of course rests on the assumption that the noise associated with each judgment is (at least somewhat) statistically independent. Thus, the crowd needs to be independent but also diversified, in order to allow a variety of answers. The answers on the ends of the spectrum will cancel each other, allowing the wisdom of the crowd phenomena to take its place. Another caveat is that individual probability judgments are often biased toward extreme values (e.g., 0 or 1). Thus any beneficial effect of multiple judgments from the same person is likely to be limited to samples from an unbiased distribution.[23] Vul and Pashler (2008) asked participants for point estimates of continuous quantities associated with general world knowledge, such as "What percentage of the world's airports are in the United States?" Without being alerted to the procedure in advance, half of the participants were immediately asked to make a second, different guess in response to the same question, and the other half were asked to do this three weeks later. The average of a participant's two guesses was more accurate than either individual guess. Furthermore, the averages of guesses made in the three-week delay condition were more accurate than guesses made in immediate succession. One explanation of this effect is that guesses in the immediate condition were less independent of each other (an anchoring effect) and were thus subject to (some of) the same kind of noise. In general, these results suggest that individual cognition may indeed be subject to an internal probability distribution characterized by stochastic noise, rather than consistently producing the best answer based on all the knowledge a person has.[23] These results were mostly confirmed in a high-powered pre-registered replication.[24] The only result that was not fully replicated was that a delay in the second guess generates a better estimate. Hourihan and Benjamin (2010) tested the hypothesis that the estimate improvements observed by Vul and Pashler in the delayed responding condition were the result of increased independence of the estimates. To do this Hourihan and Benjamin capitalized on variations in memory span among their participants. In support they found that averaging repeated estimates of those with lower memory spans showed greater estimate improvements than the averaging the repeated estimates of those with larger memory spans.[25] Rauhut and Lorenz (2011) exp contentType 24 text/html; charset=UTF-8 url 53 https://en.wikipedia.org:443/wiki/Wisdom_of_the_crowd responseCode 3 200 