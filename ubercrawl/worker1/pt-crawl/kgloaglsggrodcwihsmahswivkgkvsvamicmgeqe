kgloaglsggrodcwihsmahswivkgkvsvamicmgeqe length 6 334854 page 10048 Used to count, measure, and label For other uses, see Number (disambiguation). Set inclusions between the natural numbers (ℕ), the integers (ℤ), the rational numbers (ℚ), the real numbers (ℝ), and the complex numbers (ℂ) A number is a mathematical object used to count, measure, and label. The original examples are the natural numbers 1, 2, 3, 4, and so forth.[1] Numbers can be represented in language with number words. More universally, individual numbers can be represented by symbols, called numerals; for example, "5" is a numeral that represents the number five. As only a relatively small number of symbols can be memorized, basic numerals are commonly organized in a numeral system, which is an organized way to represent any number. The most common numeral system is the Hindu–Arabic numeral system, which allows for the representation of any number using a combination of ten fundamental numeric symbols, called digits.[2][a] In addition to their use in counting and measuring, numerals are often used for labels (as with telephone numbers), for ordering (as with serial numbers), and for codes (as with ISBNs). In common usage, a numeral is not clearly distinguished from the number that it represents. In mathematics, the notion of number has been extended over the centuries to include zero (0),[3] negative numbers,[4] rational numbers such as one half ( 1 2 ) {\displaystyle \left({\tfrac {1}{2}}\right)} , real numbers such as the square root of 2 ( 2 ) {\displaystyle \left({\sqrt {2}}\right)} and π,[5] and complex numbers[6] which extend the real numbers with a square root of −1 (and its combinations with real numbers by adding or subtracting its multiples).[4] Calculations with numbers are done with arithmetical operations, the most familiar being addition, subtraction, multiplication, division, and exponentiation. Their study or usage is called arithmetic, a term which may also refer to number theory, the study of the properties of numbers. Besides their practical uses, numbers have cultural significance throughout the world.[7][8] For example, in Western society, the number 13 is often regarded as unlucky, and "a million" may signify "a lot" rather than an exact quantity.[7] Though it is now regarded as pseudoscience, belief in a mystical significance of numbers, known as numerology, permeated ancient and medieval thought.[9] Numerology heavily influenced the development of Greek mathematics, stimulating the investigation of many problems in number theory which are still of interest today.[9] During the 19th century, mathematicians began to develop many different abstractions which share certain properties of numbers, and may be seen as extending the concept. Among the first were the hypercomplex numbers, which consist of various extensions or modifications of the complex number system. In modern mathematics, number systems are considered important special examples of more general algebraic structures such as rings and fields, and the application of the term "number" is a matter of convention, without fundamental significance.[10] History[edit] First use of numbers[edit] Main article: History of ancient numeral systems Bones and other artifacts have been discovered with marks cut into them that many believe are tally marks.[11] These tally marks may have been used for counting elapsed time, such as numbers of days, lunar cycles or keeping records of quantities, such as of animals. A tallying system has no concept of place value (as in modern decimal notation), which limits its representation of large numbers. Nonetheless, tallying systems are considered the first kind of abstract numeral system. The first known system with place value was the Mesopotamian base 60 system (c. 3400 BC) and the earliest known base 10 system dates to 3100 BC in Egypt.[12] Numerals[edit] Main article: Numeral system Numbers should be distinguished from numerals, the symbols used to represent numbers. The Egyptians invented the first ciphered numeral system, and the Greeks followed by mapping their counting numbers onto Ionian and Doric alphabets.[13] Roman numerals, a system that used combinations of letters from the Roman alphabet, remained dominant in Europe until the spread of the superior Hindu–Arabic numeral system around the late 14th century, and the Hindu–Arabic numeral system remains the most common system for representing numbers in the world today.[14][better source needed] The key to the effectiveness of the system was the symbol for zero, which was developed by ancient Indian mathematicians around 500 AD.[14] Zero[edit] This section needs additional citations for verification. Please help improve this article by adding citations to reliable sources in this section. Unsourced material may be challenged and removed. (November 2022) (template removal help) The first known documented use of zero dates to AD 628, and appeared in the Brāhmasphuṭasiddhānta, the main work of the Indian mathematician Brahmagupta. He treated 0 as a number and discussed operations involving it, including division. By this time (the 7th century) the concept had clearly reached Cambodia as Khmer numerals, and documentation shows the idea later spreading to China and the Islamic world. The number 605 in Khmer numerals, from an inscription from 683 AD. Early use of zero as a decimal figure. Brahmagupta's Brāhmasphuṭasiddhānta is the first book that mentions zero as a number, hence Brahmagupta is usually considered the first to formulate the concept of zero. He gave rules of using zero with negative and positive numbers, such as "zero plus a positive number is a positive number, and a negative number plus zero is the negative number." The Brāhmasphuṭasiddhānta is the earliest known text to treat zero as a number in its own right, rather than as simply a placeholder digit in representing another number as was done by the Babylonians or as a symbol for a lack of quantity as was done by Ptolemy and the Romans. The use of 0 as a number should be distinguished from its use as a placeholder numeral in place-value systems. Many ancient texts used 0. Babylonian and Egyptian texts used it. Egyptians used the word nfr to denote zero balance in double entry accounting. Indian texts used a Sanskrit word Shunye or shunya to refer to the concept of void. In mathematics texts this word often refers to the number zero.[15] In a similar vein, Pāṇini (5th century BC) used the null (zero) operator in the Ashtadhyayi, an early example of an algebraic grammar for the Sanskrit language (also see Pingala). There are other uses of zero before Brahmagupta, though the documentation is not as complete as it is in the Brāhmasphuṭasiddhānta. Records show that the Ancient Greeks seemed unsure about the status of 0 as a number: they asked themselves "How can 'nothing' be something?" leading to interesting philosophical and, by the Medieval period, religious arguments about the nature and existence of 0 and the vacuum. The paradoxes of Zeno of Elea depend in part on the uncertain interpretation of 0. (The ancient Greeks even questioned whether 1 was a number.) The late Olmec people of south-central Mexico began to use a symbol for zero, a shell glyph, in the New World, possibly by the 4th century BC but certainly by 40 BC, which became an integral part of Maya numerals and the Maya calendar. Maya arithmetic used base 4 and base 5 written as base 20. George I. Sánchez in 1961 reported a base 4, base 5 "finger" abacus.[16][better source needed] By 130 AD, Ptolemy, influenced by Hipparchus and the Babylonians, was using a symbol for 0 (a small circle with a long overbar) within a sexagesimal numeral system otherwise using alphabetic Greek numerals. Because it was used alone, not as just a placeholder, this Hellenistic zero was the first documented use of a true zero in the Old World. In later Byzantine manuscripts of his Syntaxis Mathematica (Almagest), the Hellenistic zero had morphed into the Greek letter Omicron (otherwise meaning 70). Another true zero was used in tables alongside Roman numerals by 525 (first known use by Dionysius Exiguus), but as a word, nulla meaning nothing, not as a symbol. When division produced 0 as a remainder, nihil, also meaning nothing, was used. These medieval zeros were used by all future medieval computists (calculators of Easter). An isolated use of their initial, N, was used in a table of Roman numerals by Bede or a colleague about 725, a true zero symbol. Negative numbers [edit] Further information: History of negative numbers The abstract concept of negative numbers was recognized as early as 100–50 BC in China. The Nine Chapters on the Mathematical Art contains methods for finding the areas of figures; red rods were used to denote positive coefficients, black for negative.[17] The first reference in a Western work was in the 3rd century AD in Greece. Diophantus referred to the equation equivalent to 4x + 20 = 0 (the solution is negative) in Arithmetica, saying that the equation gave an absurd result. During the 600s, negative numbers were in use in India to represent debts. Diophantus' previous reference was discussed more explicitly by Indian mathematician Brahmagupta, in Brāhmasphuṭasiddhānta in 628, who used negative numbers to produce the general form quadratic formula that remains in use today. However, in the 12th century in India, Bhaskara gives negative roots for quadratic equations but says the negative value "is in this case not to be taken, for it is inadequate; people do not approve of negative roots". European mathematicians, for the most part, resisted the concept of negative numbers until the 17th century, although Fibonacci allowed negative solutions in financial problems where they could be interpreted as debts (chapter 13 of Liber Abaci, 1202) and later as losses (in Flos). René Descartes called them false roots as they cropped up in algebraic polynomials yet he found a way to swap true roots and false roots as well. At the same t contentType 24 text/html; charset=UTF-8 url 40 https://en.wikipedia.org:443/wiki/Number responseCode 3 200 